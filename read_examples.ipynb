{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Header](#header)\n",
    "2. [Particles](#particles)\n",
    "3. [FFT Data](#fft)\n",
    "4. [Halo and Subhalo](#halo)<br>\n",
    "    4.1. [FOF Data](#fof)<br>\n",
    "    4.2. [SUBFIND Catalog](#subcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook gives examples of how to use read_indra.py to read in Indra data on the SciServer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import indratools as indra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the X, Y, and Z that specify the Indra run, the snapshot of the particle data (`snapnum`) and FFT data (`tnum`) for redshift 0, and the data directory (since we are not reading from the datascope). Note that when `datadir` is specified, it determines which simulation is read, and X, Y, and Z are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2 ; Y = 0; Z = 0; snapnum = 63; tnum = 504\n",
    "datadir = '/home/idies/workspace/indra/2_0_0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header\n",
    "<a id=\"header\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length data are in units of Mpc/h, velocities in km/s, and masses in MSun/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = indra.getheader(X,Y,Z,snapnum,datadir)\n",
    "print(header.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header['num_files'],header['npart'],header['mass'],header['time'],header['BoxSize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particles\n",
    "<a id=\"particles\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read positions only, no sorting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ns = indra.getpos(X,Y,Z,snapnum,datadir)\n",
    "print(pos_ns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get velocities too, and sort particles and velocities by their IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos,vel,ids = indra.getparticles(X,Y,Z,snapnum,datadir,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos[0],vel[0],np.max(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT Data\n",
    "<a id=\"fft\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading, define some functions to calculate the power spectrum of this gridded FFT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powspec(fft_re,fft_im,nbins=100,k=k):\n",
    "    # PS = fft_re^2+fft_im^2\n",
    "    # Requires k's already defined from kx,ky,kz = indra.getkvals()\n",
    "    ps = fft_re*fft_re+fft_im*fft_im\n",
    "    ps = ps[k>0] # ignore k = 0\n",
    "    k = k[k>0]\n",
    "    \n",
    "    # average PS in logarithmic bins of k\n",
    "    ps1d, kbin = np.histogram(np.log10(k),nbins,weights=ps)\n",
    "    counts = np.histogram(np.log10(k),nbins)[0]\n",
    "    ps1d = ps1d[counts>0]/counts[counts>0]\n",
    "    \n",
    "    binvals = kbin[0:nbins]+np.diff(kbin)//2\n",
    "    binvals = binvals[counts>0]\n",
    "\n",
    "    return binvals,ps1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cosmology is hard-coded here but om = header['omega0']\n",
    "def growthfunc(a, om=0.272):\n",
    "    ol = 1-om\n",
    "#    a = 1./(1.+z)\n",
    "    da=a/10000.\n",
    "    integral = 0.\n",
    "    for i in range(10000):\n",
    "        aa=(i+1)*da\n",
    "        integral+=da/((aa*np.sqrt(om/(aa**3)+ol))**3)\n",
    "\n",
    "    return 5*om/2*np.sqrt(om/a**3+ol)*integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CAMB linear power spectrum, which is normalized to z=0. (So to compare to Plin, multiply PS(z) by D(z)^2/D(z=0)^2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kth,pth = np.loadtxt('pk_indra7313_CAMB.txt',unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the k vectors. These arrays have the same shape as the FFT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kx,ky,kz = indra.getkvals()\n",
    "k = np.sqrt(kx*kx+ky*ky+kz*kz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the ratio of power spectra from the FFT data to the linear theory PS at different redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_re,fft_im,a = indra.getfft(X,Y,Z,tnum,datadir)\n",
    "bins,ps = powspec(fft_re,fft_im) # need bins to interpolate linear PS\n",
    "plin = np.interp(10**bins,kth,pth)\n",
    "norm = header['BoxSize']**3/header['npart']**2\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in np.arange(0,501,100):\n",
    "    fft_re,fft_im,a = indra.getfft(X,Y,Z,i,datadir)\n",
    "    bins,ps = powspec(fft_re,fft_im)\n",
    "    normL = growthfunc(a)**2/growthfunc(1)**2\n",
    "    plt.plot(10**bins,(ps*norm)/(plin*normL),label=\"{:.3f}\".format(a)) \n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(r'$k$ (h/Mpc)',size='large')\n",
    "plt.ylabel(r'$P(a,k)/P_{lin}(k)$',size='large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halo and Subhalo\n",
    "<a id=\"halo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FOF (or 'group') and SUBFIND headers contain the total number of groups/subhalos, and the number of files (NTask, which is always 256 for Indra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotNgroups, NTask = indra.getfofheader(X,Y,Z,snapnum,datadir)\n",
    "print(TotNgroups,NTask)\n",
    "TotNsubs,NTask = indra.getsubheader(X,Y,Z,snapnum,datadir)\n",
    "print(TotNsubs,NTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOF Data\n",
    "<a id=\"fof\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all you want is the number of particles in each FOF halo (to multiply by `header['mass']`, for example), this is given by `groupLen`. `groupOffset` then gives the information needed to index `groupids`, the particle IDs in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupLen,groupOffset = indra.getfof(X,Y,Z,snapnum,datadir)\n",
    "print(np.min(groupLen),np.max(groupLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupLen,groupOffset,groupids = indra.getfofids(X,Y,Z,snapnum,datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IDs of the particles in halo i are given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "haloIDs = groupids[groupOffset[i]:groupOffset[i]+groupLen[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some particles! I know that halo 0 doesn't cross any boundaries, so we can ignore periodic boundary conditions for now. This will only work if you called `getparticles` with `sort=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(pos[haloIDs,0],pos[haloIDs,1],'m.')\n",
    "plt.xlabel('x (Mpc/h)')\n",
    "plt.ylabel('y (Mpc/h)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subhalo Catalog\n",
    "<a id=\"subcat\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much to the FOF data, since the unbinding procedure and calculation of halo properties is done by SUBFIND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = indra.getsubcat(X,Y,Z,snapnum,datadir)\n",
    "subids = indra.getsubids(X,Y,Z,snapnum,datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cat['M200crit']),np.mean(cat['R200crit']),np.mean(np.abs(cat['SubVel'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing can get a bit tricky, so here are some examples. First let's pick a FOF group with 5 subhalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasSubs = np.where(cat['NsubPerHalo'] == 5)[0]\n",
    "thishalo = np.max(hasSubs)\n",
    "print(thishalo,cat['M200crit'][thishalo],cat['R200crit'][thishalo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IDs of the particles in this FOF halo (before unbinding) can be found via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haloIDs = groupids[groupOffset[thishalo]:groupOffset[thishalo]+groupLen[thishalo]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the indexes of the subhalos with this parent halo. We can do this in two ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(cat['subParentHalo'] == thishalo)[0])\n",
    "subindices = cat['FirstSubOfHalo'][thishalo]+np.arange(cat['NsubPerHalo'][thishalo])\n",
    "print(subindices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The halo positions are calculated for every subhalo, so let's define the center as that of the main subhalo, and take care of periodic boundary conditions. (Eventualy I will write some PBC utility functions...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxsize = header['BoxSize']\n",
    "center = cat['SubPos'][cat['FirstSubOfHalo'][thishalo],:]\n",
    "print(center)\n",
    "halopos = pos[haloIDs,:] - center\n",
    "halopos[halopos < boxsize/2.] += boxsize\n",
    "halopos[halopos > boxsize/2.] -= boxsize\n",
    "print(np.mean(halopos,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the particles in these halos! We'll plot the main halo in black first, so any particles that remain black were unbound by SUBFIND and don't belong to any subhalos (including the main `FirstSubOfHalo`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(halopos[:,0],halopos[:,1],marker = '.',color='k')\n",
    "subindices = cat['FirstSubOfHalo'][thishalo]+np.arange(cat['NsubPerHalo'][thishalo])\n",
    "colors = ['g','b','m','r','c']\n",
    "for c, i in zip(colors,subindices):\n",
    "    subIDs = subids[cat['subOffset'][i]:cat['subOffset'][i]+cat['subLen'][i]]\n",
    "    subpos = pos[subIDs,:] - center\n",
    "    subpos[subpos < boxsize/2.] += boxsize\n",
    "    subpos[subpos > boxsize/2.] -= boxsize\n",
    "    plt.scatter(subpos[:,0],subpos[:,1],marker ='.',color=c)\n",
    "plt.xlabel('x (Mpc/h)',size='large')\n",
    "plt.ylabel('y (Mpc/h)',size='large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
